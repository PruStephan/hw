\documentclass{article}

\usepackage[T2A]{fontenc}           
\usepackage[utf8]{inputenc}         
\usepackage[russian,english]{babel} 
\usepackage{amsmath,amssymb}        
\usepackage{listings}
\usepackage{cmll}
\usepackage[left=15mm, top=1cm, right=15mm, bottom=1cm, nohead, footskip=1cm]{geometry}
\usepackage{fontspec}
\usepackage[usenames]{color}
\usepackage{colortbl} 
\usepackage{misccorr} 
\setmainfont{Times New Roman}
 
\newcommand{\problem}[1]{\textbf{Problem #1} \newline}
  
\newcommand{\solution}{\textbf{Solution} \newline}
 
\newcommand{\question}[2]{
	\begin{center}
		\large{\textbf{#1 (#2)}} 
	\end{center}
}
 
\begin{document}

\begin{center}

\Huge Probability Theory

\end{center}

~\

~\

\begin{question}{Вероятностная модель эксперимента со случайными исходами. Операции над событиями и операции на множествами. Примеры}{1}

Конечное число исходов: $\Omega = \{w_1, ..., w_n\}$ - пространство элементарных событий. $w_i$ - элементарное событие

\textbf{Событие} - подмножество пространства элементарных событий

\end{question}

~\

~\


\begin{question}{Конечное вероятностное пространство. Свойства вероятности. Классическое определение вероятности}{2}

$|\Omega| = N$

$p_i \geq 0, \sum{p_i} = 1$

$P(A) = \sum\limits_{w_i \in A}{p_i}$ - \textbf{A probability}

\textbf{Свойства.....}

\textbf{Классическое определение вероятности}

$p_1 = .. = p_i = ... = p_N$

$P(A) = \dfrac{|A|}{N}$


\end{question}

~\

~\


\begin{question}{Условная вероятность. Мотивировка, определение и свойства}{3}

$P(A | B) = \dfrac{P(A \cap B)}{P(B)}$

\textit{Свойства:}

Все тривиальные

\end{question}

~\

~\

\begin{question}{Формула полной вероятности. Формула и теорема Байеса. Примеры}{4}

\textbf{Формула полной вероятности}

$A_i $ - дизъюнктное объединение дает все пространство.

$P(B) = \sum{P(B | A_i) P(A_i)}$

Тривиально

\textbf{Формула Байеса}

$P(A) > 0, P(B) > 0 \Rightarrow P(A|B) = \dfrac{P(B|A)P(A)}{P(B)}$

\textbf{Теорема Байеса}

$\Sigma = \bigsqcup{A_i}, P(B) > 0$

$P(A_k | B) = \dfrac{P(B | A_k) P(A_k)}{\sum{P(B | A_i)P(A_i)}}$

\end{question}

~\

~\

\begin{question}{Независимые события. Мотивировка и определение. Попарная независимость и независимость в совокупности}{5}

~\

~\

A, B независимы $\Leftrightarrow P(A \cap B) = P(A) P(B)$

Что равносильно тому что $P(A | B) = P(A)$

События независимы в совокупности $\Leftrightarrow \forall 1 \leq i_1 < i_2 < .. < i_k \leq n P(\bigcap{A_i}) = \prod{P(A_i)}$

\textbf{Попарная независимость слабее независимости в совокупности}

\textit{\textcolor{blue}{TODO}: Пример}

\textbf{Независимость при фиксированном k слабее независимости в совокупности}

\textit{\textcolor{blue}{TODO}: Пример}

\end{question}

\begin{question}{Схема Бернулли. Полиномиальная схема}{6}

n независимых подбрасываний несбалансированной монеты

$w = (x_1, .. x_n), x_i \in \{1, 0\}$

$\Sigma = \{w\}$

$P(w) = p^{\sum{x_i}}(1 - p)^{n - \sum{x_i}}$

Корректность.

$\sum{P(w)} = \sum{P(A_k)} = \sum{{n \choose k}p^k(1 - p)^{n - k}} = (1 + 1 - p)^n$

$B_k = \{w | x_k = 1\}$ независимы.

Набор вероятностей $\{P(A_1), ..., P(A_n)\}$

\textbf{Полиномиальная схема}

Модель: не монетка, а игральная кость с неравномерными гранями. n независимых подбрасываний

Ну все то же самое, что и со схемой Бернулли. 


\end{question}

~\

~\

\begin{question}{Теорема Эрдеша}{7}

Теорема Рамсея

$\forall k, m \exists n(k, m)$, такое что для любого графа на n вершинах существует либо клика на k вершинах, либо пустой подграф на вершинах.

$R(k, m)$ - наименьшее такое n.

Теорема Эрдеша:

$R(k, k) > 2^{k / 2}$

Берем набор из k вершин, вероятность того, что он полный или пустой равна $2^{1 - {k \choose 2}}$. Вероятность, что хоть какой то набор таков меньше суммы по всем наборам. Т.е. если ${n \choose k} 2^{1 - {k \choose 2}} < 1$, то существует граф, для которого нет такого графа.

В частности это верно для $n = 2^{k/2}$

\end{question}

~\

~\

\begin{question}{Теоремы Пуассона и Прохорова}{8}

\textbf{Теорема Пуассона}

$np_n \rightarrow \lambda > 0$

$P(S_n = k) \rightarrow \dfrac{\lambda^k e^{- \lambda}}{k!}$

\textbf{Теорема Прохорова}

$\sum\limits_{k = 0}^\infty{|P(S_n = k) - \dfrac{\lambda^k e^{- \lambda}}{k!}|} \leq \dfrac{\min{\{2, \lambda\}}}{n} 2 \lambda$

\end{question}

~\

~\

\begin{question}{Локальная теорема Муавра-Лапласа}{9}

$x = \dfrac{k - np}{\sqrt{npq}}, T$ - фиксированное число

Если $n \rightarrow \infty$, k меняется таким образом, что $|x| \leq T \Rightarrow P(S_n = k) \sim \dfrac{1}{\sqrt{2 \pi n p q}}e^{-x^2/2}$ равномерно по x.

\end{question}

~\

~\

\begin{question}{Интегральная теорема Муавра-Лапласа, оценка на скорость сходимости. Задача о театре}{10}

\end{question}

~\

~\

\begin{question}{Вероятностное пространство. Условная вероятность. Независимые события}{11}

\textbf{Колмогоровское определение вероятности}

$\Sigma$ - пространство элементарных событий

$F$ - множество случайных событий $2^\Sigma$

$P$ - мера на F, такая что $P(\Sigma) = 1$

Последовательность независимых событий - если взять любой конечный набор, он будет независим.

\end{question}

~\

~\

\begin{question}{Лемма Бореля-Кантелли. Закон нуля и единицы}{12}

$A_1, A_2, ..,$ - события. $B$ - событие "наступило бесконечное число событий из $A_1, ..$"

1. Если $\sum{P(A_i)}$ конечна, то $P(B) = 0$

$B = \bigcap_{n = 1}^\infty{\bigcup_{k = n}^\infty{A_k}}$. Отсюда очевидно первый пункт

Второй. \textcolor{blue}{TODO}

\textbf{Следствие: закон 0 и 1}: если $A_i$ независимы в совокупности, то либо $P(B) = 0$, либо $P(B) = 1$

\end{question}

~\

~\

\begin{question}{Случайная величина. Распределение с.в. Свойства функций распределения}{13}

С.в - функция из сигмы в R.

$F_\xi(x) = P(\xi \leq x)$

\textit{Свойства}

1. $0 \leq F_\xi \leq 1$

2. $F_\xi$ не убывает.

3. предел на минус беск. равен 0, предел на + беск равен 1

4. Непрерывность справа

5. $F_{\xi + c}(x) = F_\xi(x - c)$

6. $F_{c \xi}(x) = F_{\xi}(\dfrac{x}{c})$

\end{question}

~\

~\

\begin{question}{Дискретное, непрерывное и абсолютно непрерывное распределения. Свойства}{14}

\textbf{Дискретная с.в.} $\xi : \Sigma \rightarrow \{y_1, y_2, ..\}$ - не более, чем счетно

Тогда функция распределения устроена ступеньками. Распределение полностью определяется величинами $P(\xi = y_k)$

\textbf{Непрерывная с.в.}

$\forall x \in \mathbb{R} P_\xi(\{x \}) = 0$, что равносильно непрерывности слева ф. р.

\textbf{Абсолютно непрерывное распределение}

Если существует $p_\xi(t) : R \rightarrow R$ (плотность) - измеримая функция, т.ч. $F_\xi(x) = \int_{-\infty}^x{p(t) dt}$

\textit{Свойства}

1. $P_\xi (A) = \int\limits_A{p(t)}$, так как это равенство верно на лучах на минус беск., то верно и на полуинтервалах, тогда по единственности продолжения меры на полуинтервалах верно и на всех Борелевских мн-вах.

2. Плотность больше/равна нулю почти везде (так как плотность измеримая ф-ция)

3. Интеграл плотности по $R$ равен 1.

4. Плотность равна производной ф.р. почти везде

\end{question}

~\

~\

\begin{question}{Примеры вероятностных распределений}{15}

1. Биномиальные распределения: $\xi \sim Binom(n, p) \Leftrightarrow P(\xi = k) = {n \choose k} p^k (1 - p)^{n - k}$

2. Распределение Пуассона: $P(\xi = k) = \dfrac{\lambda^k e^{-\lambda}}{k!}$

3. Геометрическое распределение: $P(\xi = k) = p(1 - p)^{k - 1}$

4. Дискретное равномерное распределение: $\{y_1, ..., y_n \}$

$P(\xi = y_k) = \dfrac{1}{n}$

5. Непрерывное равномерное распрделение $p_\xi(t) = \dfrac{1}{b - a} 1_{[a, b]}(t)$

6. Нормальное распределение: $p_\xi(t) = \dfrac{1}{\sigma \sqrt{2\pi}}e^{-(t-a)^2/2 \sigma^2}$

6'. Стандартное нормальное распределение: $p_\xi(t) = \dfrac{1}{\sigma \sqrt{2\pi}}e^{-t^2/2}$

7. Экспоненциальное распределение: $p_\xi(t) = \lambda e^{-\lambda t} 1_{[0, + \infty)}(t)$

\end{question}

~\

~\

\begin{question}{Совместные распределения. Совместное распределение независимых с.в.}{16}

$\xi : \Sigma \rightarrow R^n$

$P_{\xi_1}(B) = P_{\xi}(B \times R^{n - 1})$

То есть совместная мера определяет все одномерные меры, но не наоборот (например, подбрасывания монетки могут быть зависимыми или нет).

\textbf{Случайные величины независимы, если $\forall A_1, ..., A_n \in R$ события $\xi_1 \in A_1, .., \xi_2 \in A_2, ..$ независимы}

Теорема: $\xi_1, .., \xi_n$ независимы $\Leftrightarrow P_\xi = \bigotimes{P_{\xi_i}}$ - произведение мер.

\textbf{Совместная функция распределения} (тривиально)

\textbf{Совместная плотность распределения}: ф.р. - это инетграл по n-мерной мере Лебега

\textbf{Следствие} с.в. независимы $\Leftrightarrow F_\xi (x_1, .., x_n) = F_{\xi_1} (x_1) ... F_{\xi_n} (x_n)$

Вправо: пользуемся теоремой

Влево: функция распределения однозначно определяет меру на ячейках, значит у нее единственное продолжение, и это равенство верно для $P_\xi$, дальше теорема. 

Следствие: $\xi_1, ..., \xi_n$ - абсолютно непрерывные с.в., тогда $\xi_i$ независимы $\Leftrightarrow p_\xi(t_1, .., t_n) = p_{\xi_1}(t_1) ... p_{\xi_n}(t_n)$.

По абсолютной непрерывности \textcolor{blue}{TODO}

\end{question}

~\

~\

\begin{question}{Свертки мер. Свертки мер, имеющих плотность}{17}

\textcolor{blue}{TODO}

\end{question}

~\

~\

\begin{question}{Распределение суммы независимых случайных величин. Примеры}{18}

$\xi, \eta$ - независимые случайные величины $\Rightarrow P_{\xi + \eta} = P_{\xi} * P_\eta$

$\xi + \eta \in A \Leftrightarrow (\xi, \eta) \in B \subset R^2$

$P_{\xi + \eta}(A) = P_{(\xi, \eta)}(B) = \int_{R^2}{1_B(x, y)dP_{\xi, \eta}(x, y)} = \int_{R^2}{1_A(x + y)dP_{\xi, \eta}(x, y)} = \int_{R^2}{1_A(x + y)dP_\xi(x) dP_\eta(y)}$, последнее равенство по теореме Фубини

\end{question}

~\

~\

\begin{question}{Мат ожидание. Свойства}{19}

$E_\xi = \int_\Sigma{\xi(w) dP(w)}$. 

\textit{Свойства}

1. $E\xi < + \infty \Leftrightarrow E_{|\xi|} < + \infty$

2. Линейность (линейность интеграла по мере)

3. $P(\xi \geq 0) = 1 \Rightarrow E_\xi \geq 0$

4. $P(\xi \geq \eta) = 1 \Rightarrow E_\xi \geq E_\eta$

5. $E = \int_RxdP(x)$ - из пункта 6.

6. $E_{f(\xi_1, .., \xi_n)} = \int_{R^n}{f(x_1, .., x_n) dP_{\xi_1, ..., \xi_n}(x_1, .., x_n)}$

Шаг 1: $f = 1_A \Rightarrow E_{1_A} = \int_\Sigma{1_AdP(w)} = P_{\xi_1, .., \xi_n}(A) = \int_{R^n}{1_A dP_{\xi_1, .., \xi_n}(x_1, .., x_n)}$

Шаг 2: Для простых функций все верно по линейности

Шаг 3: $f \geq 0$, берем простые, приближаем, хуячим Беппо-Леви

Шаг 4: $f = f_+ + f_-$

\end{question}

~\

~\

\begin{question}{Мат ожидание. Свойства. Медиана. Примеры}{20}

7. $\xi_1, .., \xi_n$ - независимые с.в., тогда $E_{\xi_1 ... \xi_n} = \prod$

По предыдущему пункту $E = \int_{R^n}{x_1...x_ndP_{\xi_1, .., x_n}(x_1, .., x_n)} = \int_{R^n}{x_1 .. x_n dP_{\xi_1}(x_1)...dP_{\xi_n}(x_n)}$. Смысл этого равенства в том, что мера совместной с.в. равна произведению мер, дальше просто Теорема Тоннели и все ок

8. $\xi \geq 0 \Rightarrow E = \int_0^\infty{P(\xi \geq t) dt}$ - было в теории меры.

9. Неравенство Гельдера

10. $0 < r < s \Rightarrow (E_{|\xi|^r})^{1/r} \leq (E_{|\xi|^s})^{1/s}$

Достаточно проверить для r = 1, т.к все зависит от r/s., берем неравенство Гельдера, мухлюем.

\textbf{Медиана} - такое число $a \in R : P(\xi \geq | \leq a) \geq \dfrac{1}{2}$

\end{question}

~\

~\

\begin{question}{Дисперсия. Свойства}{21}

$D = E(\xi - E)^2$

\textit{Свойства}

1. $D = E_{\xi^2} - (E_{\xi})^2$

2. $D \geq 0$

3. Если $D = 0 \Rightarrow P(\xi = const) = 1$

4. $D_{\xi + c} = D_\xi$

5. $D_{c \xi} = c^2 D_{\xi}$

7. $D_{\xi + \eta} = D_\xi + D_\eta$ для независимых

8. $E_{|\xi - E|} \leq \sqrt{D}$

\end{question}

~\

~\

\begin{question}{Неравенство Чебышева. Матожидание и дисперсия для равномерного и нормального распределений}{22}

$t, p > 0 \Rightarrow P(|\xi| \geq t) \leq \dfrac{E_{\xi}^p}{t^p}$, уже было (???)

Для равномерного распределения просто честно считаем

Для нормального тоже

\end{question}

~\

~\

\begin{question}{Независимое множество в графе}{23}

\end{question}

~\

~\

\begin{question}{Ковариация. Связь с независимостью. Коэффициент корреляции}{24}



\end{question}

~\

~\

\begin{question}{}{16}

\end{question}

~\

~\

\begin{question}{}{16}

\end{question}

~\

~\

\begin{question}{}{16}

\end{question}

~\

~\

\begin{question}{}{16}

\end{question}

~\

~\

\begin{question}{}{16}

\end{question}

~\

~\


\end{document}
